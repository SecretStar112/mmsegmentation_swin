{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flask_app.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ],
      "metadata": {
        "id": "gzOTOhX3iTzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask_ngrok\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "j47sSGxNvas1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html"
      ],
      "metadata": {
        "id": "kei8eLKV6C37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Slava-git/mmsegmentation_swin\n",
        "%cd mmsegmentation_swin\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "p4KwOXaz6EL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dependencies"
      ],
      "metadata": {
        "id": "HUqrLPe87t9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import mmcv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "import flask\n",
        "import time\n",
        "\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from mmcv import Config\n",
        "\n",
        "import mmseg\n",
        "from mmseg.apis import set_random_seed\n",
        "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
        "from mmseg.datasets.builder import DATASETS\n",
        "from mmseg.datasets.custom import CustomDataset"
      ],
      "metadata": {
        "id": "72KVpjtxqlgp"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Register dataset"
      ],
      "metadata": {
        "id": "G5AWvC0Bilbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('Background', 'Person')\n",
        "palette = [[0, 0, 0], [0, 128, 0]]"
      ],
      "metadata": {
        "id": "xL66zCUAqvRI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@DATASETS.register_module()\n",
        "class FullBodyDataset(CustomDataset):\n",
        "  CLASSES = classes\n",
        "  PALETTE = palette\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(img_suffix='.png', seg_map_suffix='.png',\n",
        "                    **kwargs)\n",
        "    assert osp.exists(self.img_dir)"
      ],
      "metadata": {
        "id": "e75cB6W-r2ef"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to google drive"
      ],
      "metadata": {
        "id": "ZpEsXG6q8N0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "id": "CkUHibBr8j3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fjIxqBjM8nEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mmsegmentation_swin"
      ],
      "metadata": {
        "id": "4ftRxNni2CuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "YRNYj8gnnfCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config.fromfile('configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py')"
      ],
      "metadata": {
        "id": "29Dex8yIsDVI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.checkpoint_config.meta = dict(\n",
        "    CLASSES= classes,\n",
        "    PALETTE= palette)\n",
        "\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "\n",
        "cfg.model.decode_head.num_classes = 2\n",
        "cfg.model.auxiliary_head.num_classes = 2\n",
        "dataset_type = 'FullBodyDataset'\n",
        "\n",
        "cfg.dataset_type = dataset_type\n",
        "cfg.data_root = '/content/drive/MyDrive/data/full_body_tik_tok'\n",
        "\n",
        "cfg.data.samples_per_gpu = 8\n",
        "cfg.data.workers_per_gpu = 8\n",
        "\n",
        "cfg.img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "cfg.crop_size = (256, 256)\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='Resize', img_scale=(540, 960), ratio_range=(0.5, 2.0)),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(type='PhotoMetricDistortion'),\n",
        "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(540, 960),\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "\n",
        "cfg.data.train.type = cfg.dataset_type\n",
        "cfg.data.train.data_root = cfg.data_root\n",
        "cfg.data.train.img_dir = 'images/training'\n",
        "cfg.data.train.ann_dir = 'annotations/training_1D'\n",
        "cfg.data.train.pipeline = cfg.train_pipeline\n",
        "\n",
        "cfg.data.val.type = cfg.dataset_type\n",
        "cfg.data.val.data_root = cfg.data_root\n",
        "cfg.data.val.img_dir = 'images/validation'\n",
        "cfg.data.val.ann_dir = 'annotations/validation_1D'\n",
        "cfg.data.val.pipeline = cfg.test_pipeline\n",
        "\n",
        "cfg.data.test.type = cfg.dataset_type\n",
        "cfg.data.test.data_root = cfg.data_root\n",
        "cfg.data.test.img_dir = 'images/validation'\n",
        "cfg.data.test.ann_dir = 'annotations/validation_1D'\n",
        "cfg.data.test.pipeline = cfg.test_pipeline\n",
        "\n",
        "cfg.load_from = '/content/drive/MyDrive/data/work_dirs/iter_20000.pth'\n",
        "cfg.work_dir = '/content/drive/MyDrive/data/work_dirs'\n",
        "\n",
        "cfg.runner.max_iters = 400\n",
        "cfg.log_config.interval = 50\n",
        "cfg.evaluation.interval = 400\n",
        "cfg.checkpoint_config.interval = 400\n",
        "\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)"
      ],
      "metadata": {
        "id": "CvObkv3pr6rH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flask "
      ],
      "metadata": {
        "id": "v6irt0_s4nA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_file = '/content/drive/MyDrive/data/work_dirs/iter_400.pth'"
      ],
      "metadata": {
        "id": "lzyWDHj2rB8l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predict(checkpoint_file, config_file, image):\n",
        "  '''\n",
        "  Get segmentation on input image\n",
        "\n",
        "  params:\n",
        "    checkpoint_file - file with weights\n",
        "    config_file - config file\n",
        "    image - path to image\n",
        "  \n",
        "  Returns:\n",
        "    predicted image\n",
        "  '''\n",
        "\n",
        "  model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
        "  result = inference_segmentor(model, image)\n",
        "  img = model.show_result(\n",
        "        image, result, palette=palette, show=False, opacity=0.5)\n",
        "  return img"
      ],
      "metadata": {
        "id": "MLIngHFu0vK3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = osp.join('static', 'images')\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "app.config[\"UPLOAD_FOLDER\"] = image_folder"
      ],
      "metadata": {
        "id": "a0xiPBjit1EL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/', methods=['GET'])\n",
        "def home():\n",
        "  return render_template('index.html')\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def predict():\n",
        "\n",
        "  imagefile = request.files['imagefile']\n",
        "  image_path = osp.join(image_folder, imagefile.filename)\n",
        "\n",
        "  imagefile.save(image_path)\n",
        "\n",
        "  input_im = osp.join(app.config['UPLOAD_FOLDER'], imagefile.filename)\n",
        "  predicted_im = make_predict(checkpoint_file, cfg, input_im)\n",
        "\n",
        "  path_pred_im = osp.join(app.config['UPLOAD_FOLDER'], 'out_'+imagefile.filename)\n",
        "  cv2.imwrite(path_pred_im, predicted_im)\n",
        "\n",
        "  time.sleep(1)\n",
        "  \n",
        "  return render_template('index.html', input_image=input_im, \n",
        "                         output_image= path_pred_im)"
      ],
      "metadata": {
        "id": "L0LRBzHPvWgz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "  app.run()"
      ],
      "metadata": {
        "id": "Vi33MmuT4UwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put your token\n",
        "!ngrok authtoken 25OVPfANFlrrKi0P95hTvzDxUKG_4Gv7J1btSjGuCTRLTAZoN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX2RRZUa4aL0",
        "outputId": "6082c967-4bb6-4a08-ea36-1f2226dd0c0a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    }
  ]
}