{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Swin_Segmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ],
      "metadata": {
        "id": "daxDkf61xwnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html"
      ],
      "metadata": {
        "id": "f4L5ONS06pjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Slava-git/mmsegmentation_swin\n",
        "%cd mmsegmentation_swin\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "d5obRayv6roY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dependencies"
      ],
      "metadata": {
        "id": "LMLn8KZKx9nO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import mmcv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from mmcv import Config\n",
        "from os import listdir,makedirs\n",
        "\n",
        "import mmseg\n",
        "from mmseg.apis import set_random_seed, train_segmentor\n",
        "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
        "from mmseg.datasets import build_dataset\n",
        "from mmseg.datasets.builder import DATASETS\n",
        "from mmseg.datasets.custom import CustomDataset\n",
        "from mmseg.models import build_segmentor"
      ],
      "metadata": {
        "id": "LBpHmY6k6s7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to google drive "
      ],
      "metadata": {
        "id": "EVw-JttkyFc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7GMsw_C6uQE",
        "outputId": "429ea9fc-9b8a-49e5-bc91-a798f81956d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs92WHIr6wR_",
        "outputId": "d0e087ba-93c0-4d5d-e8ab-5e96169fc73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pretrained weights"
      ],
      "metadata": {
        "id": "Oy1ZdJg3ySek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "!wget https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth -P checkpoints"
      ],
      "metadata": {
        "id": "s4ttexjE7EtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert masks into label format"
      ],
      "metadata": {
        "id": "NOBkxSkXyZP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/data/full_body_tik_tok/annotations/validation'\n",
        "dstpath = '/content/drive/MyDrive/data/full_body_tik_tok/annotations/validation_1D'\n"
      ],
      "metadata": {
        "id": "6Gk2YAoN-BfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_grayscale(path, dstpath):\n",
        "  '''Convert 3 channel images to grayscale\n",
        "\n",
        "  params:\n",
        "    path (str) - source folder\n",
        "    dstpath (str) - destination folder\n",
        "  '''\n",
        "  \n",
        "  try:\n",
        "    makedirs(dstpath)\n",
        "  except:\n",
        "      print (\"Directory already exist, images will be written in asme folder\")\n",
        "\n",
        "  files = [f for f in listdir(path) if osp.isfile(osp.join(path,f))] \n",
        "\n",
        "  for image in files:\n",
        "      try:\n",
        "          img = cv2.imread(osp.join(path,image))\n",
        "          gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "          dstPath = osp.join(dstpath,image)\n",
        "          cv2.imwrite(dstPath,gray)\n",
        "      except:\n",
        "          print (\"{} is not converted\".format(image))"
      ],
      "metadata": {
        "id": "wlGlZIY-z-2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/data/full_body_tik_tok/annotations/training_1D' "
      ],
      "metadata": {
        "id": "v7MPbGOX8gBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graysk_to_label(path):\n",
        "  '''Convert grayscale images to labels\n",
        "\n",
        "  params:\n",
        "    path (str) - source folder\n",
        "  '''\n",
        "  \n",
        "  files = [f for f in listdir(path) if osp.isfile(osp.join(path,f))] \n",
        "\n",
        "  for image in files:\n",
        "    img = cv2.imread(osp.join(path,image), cv2.IMREAD_UNCHANGED)\n",
        "    arr = np.array(img)\n",
        "    arr[arr == 255] = 1\n",
        "    im = Image.fromarray(arr)\n",
        "    im.save(osp.join(path, image))"
      ],
      "metadata": {
        "id": "ejxLkBiT0b47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Q3z2jmkaymoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register dataset"
      ],
      "metadata": {
        "id": "TwBp0eUHyqph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('Background', 'Person')\n",
        "pallete = [[0, 0, 0], [0, 128, 0]]"
      ],
      "metadata": {
        "id": "ZIqkuvt04sFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@DATASETS.register_module()\n",
        "class FullBodyDataset(CustomDataset):\n",
        "  CLASSES = classes\n",
        "  PALETTE = pallete\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(img_suffix='.png', seg_map_suffix='.png',\n",
        "                    **kwargs)\n",
        "    assert osp.exists(self.img_dir)"
      ],
      "metadata": {
        "id": "d0rQR01i6xo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create config file"
      ],
      "metadata": {
        "id": "Yqg-XaOSyv4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config.fromfile('mmsegmentation_swin/configs/swin/'\\\n",
        "                      'upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K.py')"
      ],
      "metadata": {
        "id": "1kE3f-Dn7Ku7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.checkpoint_config.meta = dict(\n",
        "    CLASSES= classes,\n",
        "    PALETTE= pallete)\n",
        "\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "#cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "\n",
        "cfg.model.decode_head.num_classes = 2\n",
        "cfg.model.auxiliary_head.num_classes = 2\n",
        "dataset_type = 'FullBodyDataset'\n",
        "\n",
        "cfg.dataset_type = dataset_type\n",
        "cfg.data_root = '/content/drive/MyDrive/data/full_body_tik_tok'\n",
        "\n",
        "cfg.data.samples_per_gpu = 4\n",
        "cfg.data.workers_per_gpu = 4\n",
        "\n",
        "cfg.img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "cfg.crop_size = (256, 256)\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='Resize', img_scale=(540, 960), ratio_range=(0.5, 2.0)),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(type='PhotoMetricDistortion'),\n",
        "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(540, 960),\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "\n",
        "cfg.data.train.type = cfg.dataset_type\n",
        "cfg.data.train.data_root = cfg.data_root\n",
        "cfg.data.train.img_dir = 'images/training'\n",
        "cfg.data.train.ann_dir = 'annotations/training_1D'\n",
        "cfg.data.train.pipeline = cfg.train_pipeline\n",
        "\n",
        "cfg.data.val.type = cfg.dataset_type\n",
        "cfg.data.val.data_root = cfg.data_root\n",
        "cfg.data.val.img_dir = 'images/validation'\n",
        "cfg.data.val.ann_dir = 'annotations/validation_1D'\n",
        "cfg.data.val.pipeline = cfg.test_pipeline\n",
        "\n",
        "cfg.data.test.type = cfg.dataset_type\n",
        "cfg.data.test.data_root = cfg.data_root\n",
        "cfg.data.test.img_dir = 'images/validation'\n",
        "cfg.data.test.ann_dir = 'annotations/validation_1D'\n",
        "cfg.data.test.pipeline = cfg.test_pipeline\n",
        "\n",
        "cfg.load_from = '/content/checkpoints/swin_tiny_patch4_window7_224.pth'\n",
        "cfg.work_dir = '/content/drive/MyDrive/data/swin_dirs'\n",
        "\n",
        "cfg.runner.max_iters = 30000\n",
        "cfg.log_config.interval = 200\n",
        "cfg.evaluation.interval = 3000\n",
        "cfg.checkpoint_config.interval = 3000\n",
        "\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)"
      ],
      "metadata": {
        "id": "3CO6o3B07QZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train \n"
      ],
      "metadata": {
        "id": "lmpZ1q5wzSiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(cfg):\n",
        "  '''Start training based on config file\n",
        "\n",
        "  params:\n",
        "    cfg - config file\n",
        "  '''  \n",
        "  \n",
        "  datasets = [build_dataset(cfg.data.train)]\n",
        "\n",
        "  model = build_segmentor(\n",
        "      cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "\n",
        "  model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "  mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "  train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
        "                  meta=dict())"
      ],
      "metadata": {
        "id": "08Jz3sdF7ncJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(cfg)"
      ],
      "metadata": {
        "id": "CpjE1DWczG1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "M11YmnTXzgGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_file = '/content/drive/MyDrive/data/work_dirs/iter_200.pth'"
      ],
      "metadata": {
        "id": "h9y6A0uU3N5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(checkpoint_file, config_file, image):\n",
        "  '''Predict segmentation and draw it\n",
        "\n",
        "  params:\n",
        "    checkpoint_file (str) - file with weights\n",
        "    config_file - config file\n",
        "    image (str) - path to image\n",
        "  '''\n",
        "  \n",
        "  model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
        "  result = inference_segmentor(model, image)\n",
        "  show_result_pyplot(model, image, result, pallete)"
      ],
      "metadata": {
        "id": "hhFHjDkJgkVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(checkpoint_file, cfg, \n",
        "              '/content/drive/MyDrive/data/full_body_tik_tok/images/validation/0_00030.png')"
      ],
      "metadata": {
        "id": "lKG8HMZlgMWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}